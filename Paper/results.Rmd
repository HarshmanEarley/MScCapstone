\spacing{1.1}

# Results

## Model Tuning Results  

The training and validation process yielded the following four models which were used to predict the test observations.      

- Logistic regression model of all features using a classification threshold of 0.223. This will be referred to as the "full LR" model.  
- Logistic regression model using P_2 feature as the only predictor variable using a threshold of 0.208. This will be referred to as the "reduced LR" or "simple LR" model.  
- The optimal Random Forest model best on repeated cross-validation was found to use a random sample of 20 variables at each split and generating 100 trees.  
- Deep Neural Network consisting of three hidden layers, with 160 units in each layer. A dropout of 0.5 and the first two hidden layers. $L_2$ regularization at each layer with a $\lambda$ of 0.001 and batch normalization at each layer. The Adam optimizer with default learning rate of 0.0001.


```{r echo=F,fig.align='center', out.width="48%",fig.show="hold", fig.pos="H",fig.cap="Neural Network Turning Results"}
knitr::include_graphics(c("boxplot.png","train_curve.png"))
```



## Model Comparrison

The full table of result metrics can be seen in Appendix A.[^table] In terms of accuracy, NN and RF both slightly outperform LR and achieve an accuracy that is 0.07 greater than the accuracy produced by the reduced LR model. That pattern of results is repeated in the Sensitivity. Of all the customers who defaulted in the test set, the Neural Network and Random Forest correctly identified over 90% of them. The full LR model correctly identified 85%, while the simple LR identified under 80%. The full LR model achieves the highest specificity on the test data out of the four models, with over 0.91 recorded. The simple LR model records the second highest specificity with 0.89, while both the Neural and Random Forrest recorded specificities of 0.78.

As Sensitivity has a positive effect in the calculation of the AMEX metric, it is only logical that NN and RF would fare better than the two LR models. With a value of 0.71, the NN model is the only one to record a AMEX metric greater than 0.7. The RF model records an metric value of 0.69 while the full and simple LR models achieved values of 0.61 and 0.58 respectively.

```{r echo=F,fig.align='center', out.width="60%",fig.cap="Bar Chart of Results by Model", fig.pos="H"}
knitr::include_graphics("bar.png")
```


On initial inspection, the four ROC curves produced by the model appear quite, however the ROC curves for the simple LR model and the RF model don't extend as close to the top-left of the plot as much as the full LR and the NN models. This is confirmed when comparing the Areas Under the Curve (AUC). The full LR and NN models recorded an AUC of over 0.95 while the other two models only recorded AUC's of 0.92.

```{r, echo=F,fig.align='center', out.height = "65%",out.width = "65%", fig.cap="Receiver Operating Characteristic (ROC) curve for each Model.", fig.pos="H"}

knitr::include_graphics("roc_plot.png")
```

```{r, echo=F,fig.align='center', out.height = "60%",out.width = "60%", fig.cap="FourFold Plot of Test Data Results", fig.pos="H"}
knitr::include_graphics("fourfoldplot.png")
```
The fourfold plots of the four models produced show largely similar shapes. Upon reading the corresponding section labels clear distinctions can be made. The neural network has correctly identified the most defaults. While Logistic regression has identified the most non-defaults.

[^corr]:
https://statistics.laerd.com/statistical-guides/pearson-correlation-coefficient-statistical-guide.php

[^table]:
\hyperlink{table.3}{Model Results}
