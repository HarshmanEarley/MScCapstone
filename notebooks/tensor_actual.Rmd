---
title: "R Notebook"
output: html_notebook
---


```{r, eval = FALSE}
install.packages("tensorflow")

#Next, configure R with a Python installation it can use, like this:

library(reticulate)
#path_to_python <- install_python()
virtualenv_create("r-reticulate")

#Note that if you already have Python installed, you don’t need to call install_python() and instead can just supply an absolute path to the Python executable.

#Then, use the install_tensorflow() function to install TensorFlow.

library(tensorflow)
install_tensorflow(envname = "r-reticulate")

#You can also use keras::install_keras(), which installes Tensorflow, in addition to some commonly used packages like “scipy” and “tensorflow-datasets”.

install.packages("keras")
install_keras(envname = "r-reticulate")

#You can confirm that the installation succeeded with:

library(tensorflow)
tf$constant("Hello Tensorflow!")
```



```{r}
read_metrics <- function(path, files = NULL){
  path <- paste0(path, "/")
  if ( is.null(files) ) files <- list.files(path)
  n <- length(files)
  out <- vector("list", n)
  for ( i in 1:n ) {
    dir <- paste0(path,'/', files[i], "/tfruns.d/")
    out[[i]] <- jsonlite::fromJSON(paste0(dir, "metrics.json"))
    out[[i]]$flags <- jsonlite::fromJSON(paste0(dir, "flags.json"))
    out[[i]]$evaluation <- jsonlite::fromJSON(paste0(dir, "evaluation.json"))
  }
  return(out)
}

plot_learning_curve <- function(x, ylab = NULL, cols = NULL, top = NULL, topCol = "deepskyblue2", span = 0.4, ...){
  # to add a smooth line to points
  smooth_line <- function(y) {
    x <- 1:length(y)
    out <- predict( loess(y ~ x, span = span) )
    return(out)
  }
  matplot(x, ylab = ylab, xlab = "Epochs", type = "n",...)
  grid()
  matplot(x, pch = 19, col = adjustcolor(cols, 0.3), add = TRUE)
  tmp <- apply(x, 2, smooth_line)
  tmp <- sapply( tmp, "length<-", max(lengths(tmp)) )
  cl <- rep(cols, ncol(tmp))
  cl[top] <- topCol
  matlines(tmp, lty = 1, col = cl, lwd = 2)
}
```

```{r}
# extract results
metrics <- read_metrics(glue(PATH_DB,"NN_tuningRuns3/"))
# extract validation accuracy
acc <- sapply(metrics, "[[", "val_accuracy")
loss <- sapply(metrics, "[[", "val_loss")
evaluation <- sapply(metrics, "[[", "evaluation")
```


```{r}
val_res = data.frame(
  i = 1:length(metrics),
  val_accuracy = apply(acc, 2, max, na.rm = TRUE),
  val_loss =  apply(sapply(metrics, "[[", "val_loss"), 2, min, na.rm = TRUE),
  evaluation = evaluation[2,]
)

val_res = val_res %>% arrange(-val_accuracy,val_loss)
#val_res = val_res %>% arrange(evaluation)
top3 = val_res[1:3,]
```

Plot learning curves for loss and accuracy
```{r}
par(mfrow = c(1,2))
plot_learning_curve(acc, col = adjustcolor("black", 0.3), ylim = c(0.5, 1),ylab = "Val accuracy", top = top3$i)
plot_learning_curve(loss, col = adjustcolor("black", 0.3), ylim = c(0, 1),ylab = "Val loss", top = top3$i, topCol = 'orange')
```

Boxplots
```{r}
par(mfrow = c(1,2))
boxplot(val_res$val_accuracy, outline=FALSE)
boxplot(val_res$val_loss, outline=FALSE)
```

```{r}
#Get best performing model
bestModel = as.data.frame(metrics)[1,which(colnames(as.data.frame(metrics)) %like% top3[1,]$i)]

# Replace colnames
colnames(bestModel) = colnames(as.data.frame(metrics)[,1:16])
```

```{r}
bestModelFlags$flags.epochs = 5

```


```{r}
targetPrediction = model_neuralNetwork(getFilePath("data_lastPerCustomerID",".parquet"), tuning = FALSE, bestModelFlags = bestModel)
```


Amex Prediction Score

```{r, eval = FALSE}
prediction = ifelse(targetPrediction$prediction>0.5,1,0)[,1]
NNroc = roc(response = targetPrediction$target, predictor = targetPrediction$prediction)
plot(NNroc, print.auc=TRUE)
```

```{r}
par(mfrow = c(1,2))
hist(targetPrediction$target)
hist(targetPrediction$prediction)
```
