---
title: "R Notebook"
output: html_notebook
---

```{r}
source('/Users/root1/Documents/DAC_Project/R/config.R')
```


```{r}
gc()
rowsN = 1000000

data = readFromParquet("/Users/root1/Documents/amex-default-prediction/parquet2/")  %>% slice_head(n = rowsN)
#%>%   group_by(customer_ID) %>% filter(S_2 == max(S_2)) %>% ungroup

train_labels = read_csv(getFilePath("train_labels")) %>% slice_head(n = rowsN)
train_labels[,'customer_ID'] =  as.integer(match(train_labels$customer_ID, CUSTOMER_ID))


data_y  = merge(x = data %>% select(customer_ID), y = train_labels, by = "customer_ID", all.x = TRUE)$target
#data = data  %>% dplyr::select(-c(customer_ID,S_2))
data = data  %>% dplyr::select(-customer_ID)

#Scale floats
for(i in 1:ncol(data)){
  if("double" == typeof(data[,i][[1]])){
    data[,i] = scale(data[,i][[1]])
  }
}

#One hot encode catagoricals
catCols = intersect(c('B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68','D_63','D_64'), colnames(data))
for(i in 1:length(catCols)){
  print(i)
  data = cbind(data, data %>% select(catCols[i]) %>% mutate(across(catCols[i],factor)) %>% as.data.table %>% one_hot()) %>% select(-catCols[i])
}

#Replace all remaining NA with zero
data = data %>% mutate_all(~replace(., is.na(.), 0))
```

```{r}
N = nrow(data)

i_partitions = partition(1:N, p = c(train = 0.7, valid = 0.2, test = 0.1))

# Assign dataframes
x_train = data[i_partitions$train,] %>% as.matrix()  
x_val = data[i_partitions$valid,] %>% as.matrix() 
x_test = data[i_partitions$test,] %>% as.matrix() 
rm(data)

#Assign lables
y_train = data_y[i_partitions$train]
y_val = data_y[i_partitions$valid]
y_test = data_y[i_partitions$test]
rm(data_y)

gc()
```

```{r}
N_input = ncol(x_train)

model <- keras_model_sequential() %>%
  layer_dense(units = floor(N_input/2), activation = 'sigmoid', input_shape = N_input, name = "dense1",
              kernel_regularizer = regularizer_l2(0.01)) %>%
  layer_batch_normalization(center = TRUE,scale = TRUE) %>%
  layer_dropout(rate = 0.01) %>%
  
  layer_dense(units = floor(N_input/4), activation = 'sigmoid', name = "dense2",
                            kernel_regularizer = regularizer_l2(0.01)) %>%
  layer_batch_normalization(center = TRUE,scale = TRUE) %>%
  #layer_dropout(rate = 0.01) %>%
  
  layer_dense(units = floor(N_input/8), activation = 'sigmoid', name = "dense3",
                            kernel_regularizer = regularizer_l2(0.01)) %>%
  #layer_dropout(rate = 0.01) %>%  
  
  layer_dense(units = 1, activation = 'sigmoid', name = "dense4")  %>% 
  compile(loss = 'binary_crossentropy', 
          metrics = "accuracy",
          #optimizer = optimizer_adam(learning_rate = 0.0001)
          optimizer = "adam"
  )

# training and evaluation
fit <- model %>% fit(
  x = x_train, y = y_train,
  validation_data = list(x_val, y_val),
  epochs = 5,
  batch_size = 64,
  verbose = TRUE,
  callbacks = callback_early_stopping(monitor = "val_loss", patience = 5)
)

```

```{r, eval = FALSE}
score <- model %>% evaluate(
  x_test, y_test,
  verbose = 1
)
```

